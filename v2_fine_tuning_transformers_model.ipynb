{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alyazone/Quranic-Theme-Extraction-Visualization/blob/main/v2_fine_tuning_transformers_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35d0e7a3",
      "metadata": {
        "id": "35d0e7a3",
        "outputId": "0e8f764a-d223-429c-ff05-04f9b1680ef5",
        "colab": {
          "referenced_widgets": [
            "8a499093a1434760b4320285d9a8fbb3"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a499093a1434760b4320285d9a8fbb3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1176ce12",
      "metadata": {
        "id": "1176ce12",
        "outputId": "f9e38c4d-5220-48dd-d3c5-37ba37263ed8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformers version: 4.46.3\n",
            "Datasets version: 3.1.0\n",
            "Torch version: 2.5.1+cpu\n",
            "Scikit-learn version: 1.5.2\n",
            "Sentence-Transformers version: 3.3.1\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "import datasets\n",
        "import torch\n",
        "import sklearn\n",
        "import sentence_transformers\n",
        "\n",
        "print(\"Transformers version:\", transformers.__version__)\n",
        "print(\"Datasets version:\", datasets.__version__)\n",
        "print(\"Torch version:\", torch.__version__)\n",
        "print(\"Scikit-learn version:\", sklearn.__version__)\n",
        "print(\"Sentence-Transformers version:\", sentence_transformers.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "224b8310",
      "metadata": {
        "id": "224b8310"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97355ede",
      "metadata": {
        "id": "97355ede"
      },
      "outputs": [],
      "source": [
        "# Load your dataset\n",
        "df = pd.read_csv(\"balanced-fine-tuning-dataset.csv\")\n",
        "\n",
        "# Concatenate Translation Verses and Refined Keywords\n",
        "df[\"Combined Input\"] = df[\"Translation Verses\"] + \" \" + df[\"Refined Keywords\"].apply(lambda x: \" \".join(eval(x)))\n",
        "\n",
        "# Save the combined dataset for fine-tuning\n",
        "df[[\"Combined Input\", \"Mapped Theme\"]].to_csv(\"fine-tuning-combined-input.csv\", index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a457b4b1",
      "metadata": {
        "id": "a457b4b1",
        "outputId": "e0db9139-12d5-4c74-e640-925e8c1cf3f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['Combined Input', 'Mapped Theme'],\n",
            "    num_rows: 544\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# Load the prepared dataset\n",
        "data = pd.read_csv(\"fine-tuning-combined-input.csv\")\n",
        "\n",
        "# Convert to Hugging Face Dataset\n",
        "dataset = Dataset.from_pandas(data)\n",
        "print(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30bcaaf2",
      "metadata": {
        "id": "30bcaaf2",
        "outputId": "988f6e40-6b3e-4940-ac0f-f89c0355f68e",
        "colab": {
          "referenced_widgets": [
            "6c96ec4f0e554fd38069efdadd7788a7"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c96ec4f0e554fd38069efdadd7788a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/544 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of labels: 4\n",
            "Label mapping: {np.str_('Forgiveness'): np.int64(0), np.str_('Gratitude'): np.int64(1), np.str_('Patience'): np.int64(2), np.str_('Truthfulness'): np.int64(3)}\n"
          ]
        }
      ],
      "source": [
        "# Fit the LabelEncoder with unique themes\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(dataset[\"Mapped Theme\"])  # Fit with unique labels in the dataset\n",
        "\n",
        "# Encode the labels\n",
        "dataset = dataset.map(lambda x: {\"label\": label_encoder.transform([x[\"Mapped Theme\"]])[0]})\n",
        "num_labels = len(label_encoder.classes_)\n",
        "print(f\"Number of labels: {num_labels}\")\n",
        "\n",
        "# Check the label mapping\n",
        "print(f\"Label mapping: {dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fed15b7",
      "metadata": {
        "id": "4fed15b7",
        "outputId": "5c1e0c8b-34b0-41fb-ecb1-972d1d63c1fe",
        "colab": {
          "referenced_widgets": [
            "35b31ab33bfb4abe84b9dd1c08d71caf"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35b31ab33bfb4abe84b9dd1c08d71caf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/544 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load tokenizer\n",
        "model_name = \"distilbert-base-uncased\"  # Or \"all-MiniLM-L6-v2\" for Sentence Transformers\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"Combined Input\"], truncation=True, padding=True)\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cac8adef",
      "metadata": {
        "id": "cac8adef",
        "outputId": "3a995dbf-a88d-42d0-aee6-6d1e89c3cdf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 380, Validation size: 82, Test size: 82\n",
            "{'Combined Input': 'It is God who made the night for you to rest, the day to make things visible. Indeed God is gracious to men, but most men are not grateful. rest grateful gracious', 'Mapped Theme': 'Gratitude', 'label': 1, 'input_ids': [101, 2009, 2003, 2643, 2040, 2081, 1996, 2305, 2005, 2017, 2000, 2717, 1010, 1996, 2154, 2000, 2191, 2477, 5710, 1012, 5262, 2643, 2003, 24665, 20113, 2000, 2273, 1010, 2021, 2087, 2273, 2024, 2025, 8794, 1012, 2717, 8794, 24665, 20113, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "<class 'int'>\n"
          ]
        }
      ],
      "source": [
        "# Prepare labels as tensors\n",
        "def prepare_labels(batch):\n",
        "    batch[\"labels\"] = torch.tensor(batch[\"label\"], dtype=torch.long)  # Convert 'label' to tensor\n",
        "    return batch\n",
        "\n",
        "# Step 1: Split into train+validation and test\n",
        "train_valid_test = tokenized_dataset.train_test_split(test_size=0.15, seed=42)\n",
        "train_valid = train_valid_test[\"train\"]  # 85% of the dataset\n",
        "test_dataset = train_valid_test[\"test\"]  # 15% of the dataset\n",
        "\n",
        "# Step 2: Split train+validation into train and validation\n",
        "train_valid_split = train_valid.train_test_split(test_size=0.1765, seed=42)  # ~15% of total for validation\n",
        "train_dataset = train_valid_split[\"train\"]  # 70% of the total dataset\n",
        "val_dataset = train_valid_split[\"test\"]  # 15% of the total dataset\n",
        "\n",
        "# Train dataset: 70% of the total dataset, used for model training.\n",
        "# Validation dataset: 15% of the total dataset, used for evaluating the model during training.\n",
        "# Test dataset: 15% of the total dataset, used for final evaluation after fine-tuning.\n",
        "\n",
        "# Print the sizes of each dataset\n",
        "print(f\"Train size: {len(train_dataset)}, Validation size: {len(val_dataset)}, Test size: {len(test_dataset)}\")\n",
        "\n",
        "print(train_dataset[0])  # Check the structure\n",
        "print(type(train_dataset[0][\"label\"]))  # Should print <class 'torch.Tensor'>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feae2d1d",
      "metadata": {
        "id": "feae2d1d",
        "outputId": "93191789-0b56-4989-ab71-a2d7f437bc79"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "C:\\Users\\alyam\\anaconda3\\envs\\new_env\\lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "C:\\Users\\alyam\\AppData\\Local\\Temp\\ipykernel_10752\\3246360278.py:18: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='144' max='144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [144/144 13:03, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.922865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.476091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.384135</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=144, training_loss=0.7711997032165527, metrics={'train_runtime': 790.944, 'train_samples_per_second': 1.441, 'train_steps_per_second': 0.182, 'total_flos': 48078066345120.0, 'train_loss': 0.7711997032165527, 'epoch': 3.0})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# fine-tuning process begins\n",
        "# Load pre-trained model for classification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=1,\n",
        "    logging_dir=\"./logs\",\n",
        ")\n",
        "\n",
        "# Define the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1236e8a6",
      "metadata": {
        "id": "1236e8a6",
        "outputId": "27e62dec-8d27-4825-8973-7d1392f1105d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Evaluation Results:\n",
            "{'eval_loss': 0.35183367133140564, 'eval_runtime': 17.2088, 'eval_samples_per_second': 4.765, 'eval_steps_per_second': 0.639, 'epoch': 3.0}\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test dataset\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Test Evaluation Results:\")\n",
        "print(test_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f6cc138",
      "metadata": {
        "id": "6f6cc138",
        "outputId": "892fffc0-36bd-4a9d-9a44-01e9827c57a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9390\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Forgiveness       1.00      0.86      0.93        22\n",
            "   Gratitude       0.88      0.94      0.91        16\n",
            "    Patience       0.95      1.00      0.98        20\n",
            "Truthfulness       0.92      0.96      0.94        24\n",
            "\n",
            "    accuracy                           0.94        82\n",
            "   macro avg       0.94      0.94      0.94        82\n",
            "weighted avg       0.94      0.94      0.94        82\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# verify metrics\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "predictions = trainer.predict(test_dataset)\n",
        "preds = np.argmax(predictions.predictions, axis=-1)  # Convert logits to class indices\n",
        "labels = predictions.label_ids\n",
        "\n",
        "accuracy = accuracy_score(labels, preds)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(labels, preds, target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e0dc1ca",
      "metadata": {
        "id": "1e0dc1ca",
        "outputId": "40679919-a35a-4062-c806-de13037380bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./v2_fine_tuned_theme_classifier\\\\tokenizer_config.json',\n",
              " './v2_fine_tuned_theme_classifier\\\\special_tokens_map.json',\n",
              " './v2_fine_tuned_theme_classifier\\\\vocab.txt',\n",
              " './v2_fine_tuned_theme_classifier\\\\added_tokens.json',\n",
              " './v2_fine_tuned_theme_classifier\\\\tokenizer.json')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the fine-tuned model and tokenizer\n",
        "trainer.save_model(\"./v2_fine_tuned_theme_classifier\")\n",
        "tokenizer.save_pretrained(\"./v2_fine_tuned_theme_classifier\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (new_env)",
      "language": "python",
      "name": "new_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}