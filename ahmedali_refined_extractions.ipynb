{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alyazone/Quranic-Theme-Extraction-Visualization/blob/main/ahmedali_refined_extractions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "HAsV5De0d4lM",
        "outputId": "562cdfea-61d2-4572-b9be-59cb8179581e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'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'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import re\n",
        "from transformers import pipeline\n",
        "import time"
      ],
      "metadata": {
        "id": "SHMr4elfLiiX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eDkaCs1-FOjl"
      },
      "outputs": [],
      "source": [
        "# Function to clean RAKE keywords\n",
        "def clean_keywords(keywords):\n",
        "    if isinstance(keywords, list):\n",
        "        # Convert the list into a space-separated string\n",
        "        keywords = \" \".join([str(k) for k in keywords])\n",
        "    elif isinstance(keywords, str):\n",
        "        # Clean the string directly\n",
        "        keywords = re.sub(r\"[^\\w\\s,]\", \"\", keywords)\n",
        "    else:\n",
        "        # Convert any other type into a string\n",
        "        keywords = str(keywords)\n",
        "\n",
        "    keywords = re.sub(r\"[^\\w\\s]\", \"\", keywords)  # Remove special characters\n",
        "    keywords = keywords.strip().lower()  # Convert to lowercase and strip spaces\n",
        "    return keywords\n",
        "\n",
        "# Function to refine keywords using LLM\n",
        "def refine_keywords_with_llm(keywords_list, theme, batch_size=10, max_input_length=512):\n",
        "    generator = pipeline(\"text-generation\", model=\"EleutherAI/gpt-neo-2.7B\", device=0)\n",
        "    refined_results = []\n",
        "    for i in range(0, len(keywords_list), batch_size):\n",
        "        batch_prompts = [\n",
        "            f\"Here are some extracted keywords: {str(keywords)[:max_input_length]}. \"\n",
        "            f\"The focused theme is '{theme}'. Please remove irrelevant keywords and suggest relevant ones.\"\n",
        "            for keywords in keywords_list[i:i + batch_size]\n",
        "        ]\n",
        "        try:\n",
        "            results = generator(\n",
        "                batch_prompts,\n",
        "                max_new_tokens=50,\n",
        "                truncation=True,\n",
        "                pad_token_id=generator.tokenizer.eos_token_id,\n",
        "            )\n",
        "            refined_results.extend([result[\"generated_text\"] for result in results])\n",
        "        except RuntimeError as e:\n",
        "            print(f\"Batch failed due to memory error: {e}\")\n",
        "            refined_results.extend([\"Error processing\"] * len(batch_prompts))\n",
        "    return refined_results\n",
        "\n",
        "# Define mapping of keywords to themes\n",
        "keyword_to_theme = {\n",
        "    \"truth\": \"Truthfulness\",\n",
        "    \"truthfulness\": \"Truthfulness\",\n",
        "    \"truthful\": \"Truthfulness\",\n",
        "    \"Truthfulness\": \"Truthfulness\",\n",
        "    \"honesty\": \"Truthfulness\",\n",
        "    \"honest\": \"Truthfulness\",\n",
        "    \"sincerity\": \"Truthfulness\",\n",
        "    \"sincere\": \"Truthfulness\",\n",
        "    \"sincerity\": \"Truthfulness\",\n",
        "    \"integrity\": \"Truthfulness\",\n",
        "    \"Sincerity\": \"Truthfulness\",\n",
        "    \"candor\": \"Truthfulness\",\n",
        "    \"veracity\": \"Truthfulness\",\n",
        "    \"forgiveness\": \"Forgiveness\",\n",
        "    \"mercy\": \"Forgiveness\",\n",
        "    \"Forgiving\": \"Forgiveness\",\n",
        "    \"forgive\": \"Forgiveness\",\n",
        "    \"forgiving\": \"Forgiveness\",\n",
        "    \"forgave\": \"Forgiveness\",\n",
        "    \"repent\": \"Forgiveness\",\n",
        "    \"repentence\": \"Forgiveness\",\n",
        "    \"merciful\": \"Forgiveness\",\n",
        "    \"Merciful\": \"Forgiveness\",\n",
        "    \"pardon\": \"Forgiveness\",\n",
        "    \"compassion\": \"Forgiveness\",\n",
        "    \"Compassion\": \"Forgiveness\",\n",
        "    \"patience\": \"Patience\",\n",
        "    \"Patience\": \"Patience\",\n",
        "    \"sabr\": \"Patience\",\n",
        "    \"tolerance\": \"Patience\",\n",
        "    \"Tolerance\": \"Patience\",\n",
        "    \"endurance\": \"Patience\",\n",
        "    \"resilience\": \"Patience\",\n",
        "    \"perseverance\": \"Patience\",\n",
        "    \"patient\": \"Patience\",\n",
        "    \"persevere\": \"Patience\",\n",
        "    \"serenity\": \"Patience\",\n",
        "    \"steadfastness\": \"Patience\",\n",
        "    \"gratitude\": \"Gratitude\",\n",
        "    \"Gratitude\": \"Gratitude\",\n",
        "    \"appreciation\": \"Gratitude\",\n",
        "    \"Appreciation\": \"Gratitude\",\n",
        "    \"appreciate\": \"Gratitude\",\n",
        "    \"Thankful\": \"Gratitude\",\n",
        "    \"thankful\": \"Gratitude\",\n",
        "    \"thankfulness\": \"Gratitude\",\n",
        "    \"Grateful\": \"Gratitude\",\n",
        "    \"grateful\": \"Gratitude\",\n",
        "    \"gratefulness\": \"Gratitude\",\n",
        "    \"recognition\": \"Gratitude\",\n",
        "    \"acknowledgement\": \"Gratitude\",\n",
        "    \"obligation\": \"Gratitude\",\n",
        "    \"indebtedness\": \"Gratitude\",\n",
        "    \"Obligation\": \"Gratitude\"\n",
        "}\n",
        "\n",
        "# Function to assign themes\n",
        "def assign_themes(refined_keywords):\n",
        "    themes = set()\n",
        "    for keyword in refined_keywords.split(\",\"):\n",
        "        keyword = keyword.strip()\n",
        "        if keyword in keyword_to_theme:\n",
        "            themes.add(keyword_to_theme[keyword])\n",
        "    return \", \".join(themes) if themes else \"Unknown\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of files with their corresponding themes\n",
        "files = [\n",
        "    (\"ahmedali-forgiveness-themes.csv\", \"Forgiveness\"),\n",
        "    (\"ahmedali-truthfulness-themes.csv\", \"Truthfulness\"),\n",
        "    (\"ahmedali-patience-themes.csv\", \"Patience\"),\n",
        "    (\"ahmedali-gratitude-themes.csv\", \"Gratitude\")\n",
        "]\n",
        "\n",
        "processed_data = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for file, theme in files:\n",
        "    try:\n",
        "        print(f\"Processing file: {file} for theme: {theme}\")\n",
        "        df = pd.read_csv(file)\n",
        "\n",
        "        # Check the column exists\n",
        "        if \"Extracted Keywords\" not in df.columns:\n",
        "            raise KeyError(f\"File {file} does not have 'Extracted Keywords' column.\")\n",
        "\n",
        "        # Convert 'Extracted Keywords' to Python lists\n",
        "        df[\"Extracted Keywords\"] = df[\"Extracted Keywords\"].apply(\n",
        "            lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
        "        )\n",
        "\n",
        "        print(\"Extracted Keywords after conversion:\", df[\"Extracted Keywords\"].head())\n",
        "        print(\"Type of first row:\", type(df[\"Extracted Keywords\"].iloc[0]))\n",
        "\n",
        "        # Step 1: Clean the Extracted Keywords\n",
        "        df[\"Cleaned Keywords\"] = df[\"Extracted Keywords\"].apply(clean_keywords)\n",
        "        print(\"Cleaned Keywords (after processing):\", df[\"Cleaned Keywords\"].head())\n",
        "\n",
        "        # Step 2: Convert Cleaned Keywords to a List of Strings\n",
        "        keywords_list = [str(k) for k in df[\"Cleaned Keywords\"].tolist()]\n",
        "        print(\"Keywords List (final):\", keywords_list[:5])\n",
        "\n",
        "        # Step 3: Refine Keywords with LLM\n",
        "        chunk_size = 100\n",
        "        refined_keywords = []\n",
        "        for i in range(0, len(keywords_list), chunk_size):\n",
        "            chunk = keywords_list[i:i + chunk_size]\n",
        "            refined_keywords.extend(refine_keywords_with_llm(chunk, theme))\n",
        "        df[\"Refined Keywords\"] = refined_keywords\n",
        "        print(\"Refined Keywords:\", df[\"Refined Keywords\"].head())\n",
        "\n",
        "        # Step 4: Assign Themes\n",
        "        df[\"Themes\"] = df[\"Refined Keywords\"].apply(assign_themes)\n",
        "        print(\"Themes:\", df[\"Themes\"].head())\n",
        "\n",
        "        processed_data.append(df)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {file}: {e}\")"
      ],
      "metadata": {
        "id": "_tm2OrZHPtNg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98991703-7abc-48ce-b67a-7de5b3bf56f2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: ahmedali-forgiveness-themes.csv for theme: Forgiveness\n",
            "Raw Extracted Keywords: 0    ['name', 'merciful', 'ever', 'benevolent', 'al...\n",
            "1                   ['merciful', 'ever', 'beneficent']\n",
            "2    ['lord sent commands', 'turned towards', 'kind...\n",
            "3              ['pardoned', 'may', 'grateful', 'even']\n",
            "4    ['softened towards', 'moses said', 'lord .\"', ...\n",
            "Name: Extracted Keywords, dtype: object\n",
            "Cleaned Keywords (after processing): 0                  name merciful ever benevolent allah\n",
            "1                             merciful ever beneficent\n",
            "2    lord sent commands turned towards kind indeed ...\n",
            "3                           pardoned may grateful even\n",
            "4    softened towards moses said lord  lord turn ta...\n",
            "Name: Cleaned Keywords, dtype: object\n",
            "Error processing file ahmedali-forgiveness-themes.csv: list indices must be integers or slices, not str\n",
            "Processing file: ahmedali-truthfulness-themes.csv for theme: Truthfulness\n",
            "Raw Extracted Keywords: 0    ['surah like', 'like', 'witness', 'votary', 't...\n",
            "1    ['gave adam knowledge', 'truthful .\"', 'things...\n",
            "2    ['truth knowingly', 'confuse truth', 'falsehoo...\n",
            "3    ['gave moses', 'truth', 'remember', 'may', 'gu...\n",
            "4    ['truth ,\"', 'good shape', 'brought us', 'blem...\n",
            "Name: Extracted Keywords, dtype: object\n",
            "Cleaned Keywords (after processing): 0    surah like like witness votary truthful reveal...\n",
            "1    gave adam knowledge truthful  things tell set ...\n",
            "2      truth knowingly confuse truth falsehood conceal\n",
            "3    gave moses truth remember may guided falsehood...\n",
            "4    truth  good shape brought us blemish  moses sa...\n",
            "Name: Cleaned Keywords, dtype: object\n",
            "Error processing file ahmedali-truthfulness-themes.csv: list indices must be integers or slices, not str\n",
            "Processing file: ahmedali-patience-themes.csv for theme: Patience\n",
            "Raw Extracted Keywords: 0    ['shall try', 'labour );', 'give tidings', 'we...\n",
            "1    ['give us endurance', 'help us', 'truth .\"', '...\n",
            "2    ['hear many untoward things', 'straight path',...\n",
            "3    ['may find success', 'fear god', 'suffering', ...\n",
            "4    ['yet god may', 'take perforce', 'open adulter...\n",
            "Name: Extracted Keywords, dtype: object\n",
            "Cleaned Keywords (after processing): 0    shall try labour  give tidings wealth sure som...\n",
            "1    give us endurance help us truth  facing goliat...\n",
            "2    hear many untoward things straight path human ...\n",
            "3    may find success fear god suffering strengthen...\n",
            "4    yet god may take perforce open adultery much g...\n",
            "Name: Cleaned Keywords, dtype: object\n",
            "Error processing file ahmedali-patience-themes.csv: list indices must be integers or slices, not str\n",
            "Processing file: ahmedali-gratitude-themes.csv for theme: Gratitude\n",
            "Raw Extracted Keywords: 0    ['devotional obligations', 'unknown', 'spend',...\n",
            "1              ['pardoned', 'may', 'grateful', 'even']\n",
            "2    ['word ), except', 'went back', 'others ),\"', ...\n",
            "3    ['send ahead', 'devotional obligations', 'zaka...\n",
            "4    ['give thanks', 'shall remember', 'remember', ...\n",
            "Name: Extracted Keywords, dtype: object\n",
            "Cleaned Keywords (after processing): 0    devotional obligations unknown spend given ful...\n",
            "1                           pardoned may grateful even\n",
            "2    word  except went back others  give zakat due ...\n",
            "3    send ahead devotional obligations zakat sees p...\n",
            "4    give thanks shall remember remember ungrateful...\n",
            "Name: Cleaned Keywords, dtype: object\n",
            "Error processing file ahmedali-gratitude-themes.csv: list indices must be integers or slices, not str\n",
            "No data was processed. Check your input files.\n"
          ]
        }
      ]
    }
  ]
}